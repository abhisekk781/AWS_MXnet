{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2689c52bf49c4e98395b76fff8836e9",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Module 5 Lesson 4 Practice Assessment\n",
    "\n",
    "This lesson covered how to write a training loop in MXNet with the Gluon API and how to write a validation loop to evaluate a trained network. This practice assessment will allow you to become more familiar with these concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "621c34526a57cbbcd1f295c35014653c",
     "grade": false,
     "grade_id": "cell-359ed2e0f0c07249",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd, gluon, init, autograd, metric\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "019f7728e0251afe3ad28b132fb5d2a8",
     "grade": false,
     "grade_id": "cell-9dbb4ff8268cf6f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "M5_DATA = Path(os.getenv('DATA_DIR', '../../data'), 'module_5')\n",
    "M5_IMAGES = Path(M5_DATA, 'images')\n",
    "M5_MODELS = Path(M5_DATA, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9acccf4927be7a5d4da0180ab2d3937",
     "grade": false,
     "grade_id": "cell-276e56d96b09e097",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "First, let's prepare the dataset we'll use for the training exercise. We will take the popular MNIST dataset but convert the labels so that it becomes a binary classification problem. To do this, we will simply set the label of all digits greater than 0 to 1. This means that we now have two labels. 0 for digit images that correspond to the handwritten 0 and 1 for all other digits in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67f5059af6ffcbeeebdf859f733e785b",
     "grade": false,
     "grade_id": "cell-1e5132daa54bafcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(train=True, root=M5_IMAGES)\n",
    "train_data._label[train_data._label > 0] = 1\n",
    "\n",
    "val_data = datasets.MNIST(train=False, root=M5_IMAGES)\n",
    "val_data._label[val_data._label > 0] = 1\n",
    "\n",
    "batch_size = 128\n",
    "train_data = gluon.data.DataLoader(train_data.transform_first(transforms.ToTensor()),\n",
    "                                  batch_size = batch_size,\n",
    "                                   shuffle=True)\n",
    "val_data = gluon.data.DataLoader(val_data.transform_first(transforms.ToTensor()),\n",
    "                                 batch_size = batch_size,\n",
    "                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f9afaceee08fa4d524b00e61a5a9ae8",
     "grade": false,
     "grade_id": "cell-068d2a69ea3b24d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 1\n",
    "\n",
    "Now you will get some practice defining a network that solve the binary classification task. Fill in the function to define a network based on the LeNet architecture from the lesson but instead of 10 output layers for the original MNIST data, you should have 2 output layers for the modified task. The function should also return the loss function for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3391433804f81df3db4619d3fdc9137",
     "grade": false,
     "grade_id": "network",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_network():\n",
    "    \"\"\"\n",
    "    Should create the LeNet 10 network but with 2 output units instead of 10 and return a classification loss function\n",
    "    \n",
    "    :return: the network and the loss function\n",
    "    :rtype: (gluon.Block, gluon.Block)\n",
    "    \"\"\"\n",
    "    \n",
    "    net = None\n",
    "    loss_fn = None\n",
    "    \n",
    "    # create a newtork\n",
    "    # YOUR CODE HERE\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            nn.Conv2D(channels=6,kernel_size=5,activation='relu'),\n",
    "            nn.MaxPool2D(pool_size=2,strides=2),\n",
    "            nn.Conv2D(channels=16,kernel_size=3,activation='relu'),\n",
    "            nn.MaxPool2D(pool_size=2,strides=2),\n",
    "            nn.Dense(120, activation='relu'),\n",
    "            nn.Dense(84, activation='relu'),\n",
    "            nn.Dense(2))\n",
    "    \n",
    "    net.initialize(init=init.Xavier())\n",
    "    \n",
    "    # choose and set loss_fn for a classification task\n",
    "    # YOUR CODE HERE\n",
    "    loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    return net, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff89877b3179a15f90af1553d2be2164",
     "grade": true,
     "grade_id": "cell-45b64f058f5bfde6",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n, loss_fn = get_network()\n",
    "\n",
    "assert isinstance(n[0], nn.Conv2D)\n",
    "assert isinstance(n[2], nn.Conv2D)\n",
    "assert isinstance(n[1], nn.MaxPool2D)\n",
    "assert isinstance(n[3], nn.MaxPool2D)\n",
    "\n",
    "for l in n[-3:]:\n",
    "    assert isinstance(l, nn.Dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a767fdc3ff413daaca7018bd508d1438",
     "grade": false,
     "grade_id": "cell-43ee1657d75563e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you implemented the above function correctly, the code cell below should print a 7 layer neural network similar to LeNet but with the final layer being a 2 unit fully-connected or Dense Layer. It should also print a description of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc5955992256d020782b43dd6ba1bd0d",
     "grade": false,
     "grade_id": "cell-b7e129d1377cd465",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sequential(\n",
      "  (0): Conv2D(None -> 6, kernel_size=(5, 5), stride=(1, 1), Activation(relu))\n",
      "  (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
      "  (2): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), Activation(relu))\n",
      "  (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
      "  (4): Dense(None -> 120, Activation(relu))\n",
      "  (5): Dense(None -> 84, Activation(relu))\n",
      "  (6): Dense(None -> 2, linear)\n",
      "), SoftmaxCrossEntropyLoss(batch_axis=0, w=None))\n"
     ]
    }
   ],
   "source": [
    "print(get_network())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af1e24bd008aff75ddaa67d4c8fd6a31",
     "grade": false,
     "grade_id": "cell-28e9acc399e665c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "In the function definition below write the training loop so you can use the function to train the network you defined earlier. As training progress, print out the current loss and training accuracy metric after every epoch. The loss function is passed in to the function as an argument but you can create a metric accumulator for accuracy using `mxnet.metric.Accuracy`. For model parameter updates you will need to construct a trainer. Use the following values for the optimization hyperparameters.\n",
    "\n",
    "* optimizer - `sgd`\n",
    "* learning_rate - `0.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d77b684db943bcd93bef68b54d3b8524",
     "grade": false,
     "grade_id": "train",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train(net, loss_fn, train_data, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Should take an initialized network and train that network using data from the data loader.\n",
    "    \n",
    "    :param network: initialized gluon network to be trained\n",
    "    :type network: gluon.Block\n",
    "    \n",
    "    :param loss_fn: the loss function\n",
    "    :type loss_fn: gluon.Block\n",
    "    \n",
    "    :param train_data: the training DataLoader provides batches for data for every iteration\n",
    "    :type train_data: gluon.data.DataLoader\n",
    "    \n",
    "    :param epochs: number of epochs to train the DataLoader\n",
    "    :type epochs: int\n",
    "    \n",
    "    :param batch_size: batch size for the DataLoader.\n",
    "    :type batch_size: int\n",
    "    \n",
    "    :return: tuple of trained network and the final training accuracy\n",
    "    :rtype: (gluon.Block, float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    trainer = gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':0.1})\n",
    "    train_acc = metric.Accuracy()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss= 0.\n",
    "        for data, label in train_data:    # Iterate through the training dataset\n",
    "            with autograd.record():    # Record gradient of error \n",
    "                output = net(data)        # Forward pass \n",
    "                loss = loss_fn(output, label)     # get Loss \n",
    "            loss.backward()   # Back propagate \n",
    "            trainer.step(batch_size)\n",
    "            train_loss += loss.mean().asscalar()\n",
    "            train_acc.update(label,output) #Gluon Metric accuracy\n",
    "        \n",
    "    return (net, train_acc.get()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2672f304ef2dd9eb266cbe95db4225f2",
     "grade": false,
     "grade_id": "cell-19a2a52e065d0413",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We're running through the dataset twice (i.e. 2 epochs) in the next cell, so this could take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80f8fcaa9c6b0176e634d67c2bbd44c4",
     "grade": true,
     "grade_id": "cell-57ea0a4606874ada",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n, ta = train(*get_network(), train_data, 2, batch_size)\n",
    "assert ta >= .98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92eeb57c3dad4097e25553ee3c6fff2a",
     "grade": false,
     "grade_id": "cell-6fffd482025432fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you have implemented the function above correctly, the code below should print a line after every epoch and you should the loss go down and the accuracy go up. After 5 epochs you should have accuracies that are well past .99 (but this might take a few minutes to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "330fa82f61848a2ca005ddf311158460",
     "grade": false,
     "grade_id": "cell-47331cc63ad50233",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-15201d38bab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-49e748d9f34d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, loss_fn, train_data, epochs, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# get Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Back propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Gluon Metric accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mxnet/gluon/trainer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch_size, ignore_stale_grad)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allreduce_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_stale_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mallreduce_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mxnet/gluon/trainer.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, ignore_stale_grad)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mupd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                     \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                     \u001b[0mupdater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, index, grad, weight)\u001b[0m\n\u001b[1;32m   1697\u001b[0m                         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m                         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m                         states)\n\u001b[0m\u001b[1;32m   1700\u001b[0m                     \u001b[0mcurrent_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py\u001b[0m in \u001b[0;36mupdate_multi_precision\u001b[0;34m(self, index, weight, grad, state)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0muse_multi_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_precision\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         self._update_impl(index, weight, grad, state,\n\u001b[0;32m--> 654\u001b[0;31m                           multi_precision=use_multi_precision)\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_update_impl\u001b[0;34m(self, indices, weights, grads, states, multi_precision)\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                     multi_sgd_update(*_flatten_list(zip(weights, grads)), out=weights,\n\u001b[0;32m--> 617\u001b[0;31m                                      num_weights=len(weights), lrs=lrs, wds=wds, **kwargs)\n\u001b[0m\u001b[1;32m    618\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mmulti_sgd_update\u001b[0;34m(*data, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net, ta = train(*get_network(), train_data, 5, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b5cba3a4555642bbb791d92240f0f6d",
     "grade": false,
     "grade_id": "cell-e35f60204380c3db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Question 3\n",
    "\n",
    "Now fill in the function below to evaluate the model on the validation dataset. The function should only do one pass through the validation dataset and should report back the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c722f2d13e1fd4e7be136bfd24fdc7d6",
     "grade": false,
     "grade_id": "validate",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(network, dataloader):\n",
    "    \"\"\"\n",
    "    Should compute the accuracy of the network on the validation set.\n",
    "    \n",
    "    :param network: initialized gluon network to be trained\n",
    "    :type network: gluon.Block\n",
    "    \n",
    "    :param dataloader: the validation DataLoader provides batches for data for every iteration\n",
    "    :type dataloader: gluon.data.DataLoader\n",
    "    \n",
    "    :return: validation accuracy\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    valid_acc = metric.Accuracy()\n",
    "    for data, label in dataloader:  # Validation Loop ~~ \n",
    "        valid_acc.update(label, network(data))\n",
    "    return valid_acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b2945245b240bafe5a46da9a41a0631",
     "grade": true,
     "grade_id": "cell-7de9f040506452ff",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c58211cab36b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.98\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "assert evaluate(net, val_data) > .98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccaf6b9dfdbe710b359d6afedfd5b693",
     "grade": false,
     "grade_id": "cell-7beab9f627e1e7a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you implemented the function above correctly, then the cell below should print a validation accuracy of around 0.99 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b26ebc9ded9f87bc4b11c887356171fa",
     "grade": false,
     "grade_id": "cell-412016fc5caf4711",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Validation Acc: %.3f \"%(evaluate(net, val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "assignment_name": "module_5_practice_2",
   "assignment_version": 2,
   "course_slug": "aws-computer-vision-gluoncv",
   "graded_item_id": "msW9J",
   "launcher_item_id": "GbekO"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
